### 问题一、什么是监督学习，无监督学习，半监督学习
+ 答：有监督学习，不仅把训练数据丢给计算机，而且还把分类的结果也一并给计算机分析。计算机学习之后，把新的未知数据丢给它，它会根据之前训练学习的模型来计算新的结果概率，给出一个最接近正确的结果。常用的监督学习算法：分类或回归。
无监督学习，只给训练的数据，不给结果，计算机无法准确知道哪些数据具有哪些标签，只能通过分析原有数据之间的特征，从而对原有数据进行聚焦，得到一些集合，同一个集合之间的特征相似度较高。同一个集合与另一个集合相似度越远，即组间相似度尽可能越，组内相似度尽可能相近。常见的算法有：聚类算法
半监督学习，有监督学习和无监督学习的中间带就是半监督学习。对于半监督学习，其训练数据，一部分是有标签的，另一部分没有标签，而没标签数据的数量远远大于有标签数据数量。常见算法：半监督分类、半监督回归、半监督降维

###  问题二、K-means中的k值如何选取
+ 常见的方法有手肘法和轮廓系数法。、
+ 手肘法的核心指标是误差平方和。核心思想：随着聚类K的增大，样本划分更加精细，每个族的聚合程度会逐渐提高，误差平方和减少。当聚类的K值快到达真实聚类数十，再增加K所得到的聚类程度回报会迅速变小，此时误差平方和变动趋于平缓。
轮廓系数，原理主要使得簇内样本的距离越近，簇间样本距离越远，平均轮廓系数越大，聚类效果越好。即平均轮廓系数最大的K便是最佳聚类数。平均轮廓系数的取值【-1，1】

###  问题三、随机森林采用了bagging集成学习，bagging指的是什么
+ bagging，是一种根据均匀概率分布从数据中重复（有放回）的技术。
  + 从样本集中用Boostrap采样选出n个训练样本
  + 在所有属性上，用这n个样本训练分类器
  + 重复以上两步m次，就可以得到m个分类器
  + 将数据放在这m个分类器上跑，最后投票机制
  + 对于分类问题，有投票表决产生分类结果；对于回归问题，由n个模型预测结果的均值作为最后预测结果。

### 问题四、主动学习和半监督学习的区别是什么
+ 主动学习，对于一堆不带标签的数据，通过选择策略，主动选择一部分数据让专家进行标注
  半监督学习，对于不带标签的数据，通过原有数据模型训练，自动补全标签。
  主动选择，因为自行选择想要学习的数据，所以用较少的训练数据，往往也可以表现得很好。
  半监督学习，模型训练的数据集是随机选择，往往需要较多的训练数据集，才能对模型特征更好的提取，从而使得预测的模型效果更好。
